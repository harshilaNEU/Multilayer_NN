{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: -0.4624\n",
      "Iteration: 100, Loss: -56.2995\n",
      "Iteration: 200, Loss: -56.3670\n",
      "Iteration: 300, Loss: -56.3884\n",
      "Iteration: 400, Loss: -56.3974\n",
      "Iteration: 500, Loss: -56.4017\n",
      "Iteration: 600, Loss: -56.4043\n",
      "Iteration: 700, Loss: -56.4062\n",
      "Iteration: 800, Loss: -56.4078\n",
      "Iteration: 900, Loss: -56.4092\n",
      "Layer 1: 64 neurons, Activation: relu\n",
      "Layer 2: 32 neurons, Activation: relu\n",
      "Layer 3: 16 neurons, Activation: relu\n",
      "Layer 4: 1 neurons, Activation: sigmoid\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# CIFAR-10 class names to integer labels mapping\n",
    "label_map = {\n",
    "    'airplane': 0,\n",
    "    'automobile': 1,\n",
    "    'bird': 2,\n",
    "    'cat': 3,\n",
    "    'deer': 4,\n",
    "    'dog': 5,\n",
    "    'frog': 6,\n",
    "    'horse': 7,\n",
    "    'ship': 8,\n",
    "    'truck': 9\n",
    "}\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in sorted(os.listdir(folder)):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        if not os.path.isdir(label_folder):\n",
    "            continue\n",
    "        for image_file in os.listdir(label_folder):\n",
    "            image_path = os.path.join(label_folder, image_file)\n",
    "            with Image.open(image_path) as img:\n",
    "                img = img.resize((32, 32))\n",
    "                img_array = np.asarray(img, dtype=np.float32) / 255.0\n",
    "                images.append(img_array.flatten())\n",
    "                labels.append(label_map[label])\n",
    "    images = np.array(images).T\n",
    "    labels = np.array(labels).reshape(1, -1)\n",
    "    return images, labels\n",
    "\n",
    "class Activation:\n",
    "    @staticmethod\n",
    "    def relu(z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    @staticmethod\n",
    "    def d_relu(z):\n",
    "        return np.where(z > 0, 1.0, 0.0)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    @staticmethod\n",
    "    def d_sigmoid(z):\n",
    "        s = Activation.sigmoid(z)\n",
    "        return s * (1 - s)\n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size) * 0.1\n",
    "        self.biases = np.zeros((output_size, 1))\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.params = Parameters(input_size, output_size)\n",
    "        self.activation = activation\n",
    "        self.z = None\n",
    "        self.a = None\n",
    "        self.a_prev = None\n",
    "\n",
    "    def forward(self, a_prev):\n",
    "        self.a_prev = a_prev\n",
    "        self.z = np.dot(self.params.weights, a_prev) + self.params.biases\n",
    "        self.a = getattr(Activation, self.activation)(self.z)\n",
    "        return self.a\n",
    "\n",
    "    def backward(self, dA, learning_rate):\n",
    "        m = self.a_prev.shape[1]\n",
    "        dZ = dA\n",
    "        if self.activation == 'relu':\n",
    "            dZ = dA * Activation.d_relu(self.z)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            dZ = dA * Activation.d_sigmoid(self.z)\n",
    "        dW = np.dot(dZ, self.a_prev.T) / m\n",
    "        dB = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "        dA_prev = np.dot(self.params.weights.T, dZ)\n",
    "\n",
    "        self.params.weights -= learning_rate * dW\n",
    "        self.params.biases -= learning_rate * dB\n",
    "        return dA_prev\n",
    "\n",
    "class DeepNeuralNetwork:\n",
    "    def __init__(self, layers_dims, learning_rate=0.001, iterations=1000):\n",
    "        self.layers = [Layer(layers_dims[i], layers_dims[i+1], 'relu') for i in range(len(layers_dims)-2)]\n",
    "        self.layers.append(Layer(layers_dims[-2], layers_dims[-1], 'sigmoid'))  # Output layer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        a = X\n",
    "        for layer in self.layers:\n",
    "            a = layer.forward(a)\n",
    "        return a\n",
    "\n",
    "    def compute_loss(self, y, y_hat):\n",
    "        epsilon = 1e-7  # Small constant to prevent log(0)\n",
    "        y_hat_clipped = np.clip(y_hat, epsilon, 1 - epsilon)  # Clip y_hat to avoid log(0)\n",
    "        m = y.shape[1]\n",
    "        loss = -np.mean(y * np.log(y_hat_clipped) + (1 - y) * np.log(1 - y_hat_clipped))\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def backward_propagation(self, y, y_hat):\n",
    "        epsilon = 1e-7\n",
    "        dA = -(y / np.clip(y_hat, epsilon, 1 - epsilon)) + ((1 - y) / np.clip(1 - y_hat, epsilon, 1 - epsilon))\n",
    "        for layer in reversed(self.layers):\n",
    "            dA = layer.backward(dA, self.learning_rate)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for i in range(self.iterations):\n",
    "            y_hat = self.forward_propagation(X)\n",
    "            loss = self.compute_loss(y, y_hat)\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Iteration: {i}, Loss: {loss:.4f}\")\n",
    "            self.backward_propagation(y, y_hat)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_hat = self.forward_propagation(X)\n",
    "        predictions = y_hat > 0.5\n",
    "        return predictions\n",
    "\n",
    "    def print_model(self):\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            print(f\"Layer {i}: {layer.params.weights.shape[0]} neurons, Activation: {layer.activation}\")\n",
    "\n",
    "# Define the architecture and hyperparameters\n",
    "layers_dims = [3072, 64, 32, 16, 1]  # Example architecture\n",
    "learning_rate = 0.001\n",
    "iterations = 1000\n",
    "\n",
    "# Initialize and train the network\n",
    "dnn = DeepNeuralNetwork(layers_dims, learning_rate, iterations)\n",
    "# Assuming X_train and y_train are already loaded\n",
    "X_train, y_train = load_images_from_folder('data/train')  # Ensure this path is correct\n",
    "dnn.train(X_train, y_train)\n",
    "dnn.print_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
